#!/usr/bin/env python3
"""
Pre-exploitation phase module for APTES
"""

import re
import logging
from datetime import datetime

from phases.base import PhaseBase
from lib import validators, webanalysis
from utils import reporting

# Check for optional imports
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

try:
    import concurrent.futures
    CONCURRENT_AVAILABLE = True
except ImportError:
    CONCURRENT_AVAILABLE = False

try:
    from openpyxl.styles import PatternFill
    EXCEL_AVAILABLE = True
except ImportError:
    EXCEL_AVAILABLE = False

class PreExploitationPhase(PhaseBase):
    """Pre-Exploitation Phase Controller"""
    
    def __init__(self, framework):
        """Initialize the Pre-Exploitation phase controller"""
        super().__init__(framework)
        
        # Get recon results from framework
        self.recon_results = framework.results.get("recon", {})
        
        # Initialize phase-specific results
        self.results.update({
            "vulnerability_validation": {},
            "webapp_analysis": {},
            "credential_testing": {},
            "payload_generation": {},
            "attack_vectors": []
        })
        
        # Risk colors for reports
        if EXCEL_AVAILABLE:
            self.risk_colors = {
                "critical": PatternFill(start_color="FF0000", end_color="FF0000", fill_type="solid"),
                "high": PatternFill(start_color="FFA500", end_color="FFA500", fill_type="solid"),
                "medium": PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid"),
                "low": PatternFill(start_color="00FF00", end_color="00FF00", fill_type="solid"),
                "info": PatternFill(start_color="ADD8E6", end_color="ADD8E6", fill_type="solid")
            }
    
    def _execute(self, exploit_filter=None, skip_web=False, skip_creds=False, skip_payloads=False):
        """
        Execute pre-exploitation phase operations
        
        Args:
            exploit_filter (dict): Filter for vulnerabilities and attacks
            skip_web (bool): Skip web application analysis
            skip_creds (bool): Skip credential testing
            skip_payloads (bool): Skip payload generation
        """
        self.logger.info(f"Starting pre-exploitation analysis for {self.target}")
        
        # Validate vulnerabilities
        self.validate_vulnerabilities()
        
        # Perform web application analysis if not skipped
        if not skip_web:
            self.analyze_web_applications()
        
        # Test default credentials if not skipped
        if not skip_creds:
            self.test_default_credentials()
        
        # Generate payloads if not skipped
        if not skip_payloads:
            self.generate_payloads()
        
        # Identify attack vectors
        self.identify_attack_vectors(exploit_filter)
        
        self.logger.info(f"Pre-exploitation analysis completed for {self.target}")
        return self.results
    
    def validate_vulnerabilities(self):
        """
        Validate vulnerabilities from reconnaissance phase
        
        Returns:
            list: Validated vulnerabilities
        """
        self.logger.info("Validating vulnerabilities")
        
        validated_vulns = []
        
        # Extract vulnerabilities from recon results
        if self.recon_results and "active" in self.recon_results and "vulnerabilities" in self.recon_results["active"]:
            vulns = self.recon_results["active"]["vulnerabilities"].get("vulnerabilities", [])
            
            # Process each vulnerability
            for vuln in vulns:
                validated_vuln = validators.validate_vulnerability(self.target, vuln, verify_ssl=self.verify_ssl)
                if validated_vuln:
                    validated_vulns.append(validated_vuln)
        
        # Add manual vulnerability checks
        if self.recon_results and "active" in self.recon_results and "ports" in self.recon_results["active"]:
            for host, host_data in self.recon_results["active"]["ports"].items():
                for proto, proto_data in host_data.items():
                    for port, port_data in proto_data.items():
                        service = port_data.get("service", "").lower()
                        product = port_data.get("product", "").lower()
                        version = port_data.get("version", "")
                        
                        # Check for potential vulnerabilities
                        manual_vulns = validators.check_known_vulnerabilities(host, port, service, product, version)
                        validated_vulns.extend(manual_vulns)
        
        # Group vulnerabilities by host and service
        grouped_vulns = {}
        for vuln in validated_vulns:
            host = vuln.get("host", self.target)
            service = vuln.get("service", "unknown")
            
            if host not in grouped_vulns:
                grouped_vulns[host] = {}
            
            if service not in grouped_vulns[host]:
                grouped_vulns[host][service] = []
            
            grouped_vulns[host][service].append(vuln)
        
        self.results["vulnerability_validation"] = {
            "vulnerabilities": validated_vulns,
            "grouped": grouped_vulns,
            "total_count": len(validated_vulns)
        }
        
        self.logger.info(f"Validated {len(validated_vulns)} vulnerabilities")
        return validated_vulns
    
    def analyze_web_applications(self):
        """
        Analyze web applications for vulnerabilities
        
        Returns:
            dict: Analysis results
        """
        self.logger.info("Analyzing web applications")
        
        web_services = []
        
        # Extract web services from recon results
        if self.recon_results and "active" in self.recon_results and "ports" in self.recon_results["active"]:
            for host, host_data in self.recon_results["active"]["ports"].items():
                for proto, proto_data in host_data.items():
                    for port, port_data in proto_data.items():
                        service = port_data.get("service", "").lower()
                        if "http" in service or port in ["80", "443", "8080", "8443"]:
                            protocol = "https" if port in ["443", "8443"] or "https" in service else "http"
                            web_services.append({
                                "host": host,
                                "port": port,
                                "url": f"{protocol}://{host}:{port}"
                            })
        
        # If no web services found in recon, try common ports
        if not web_services:
            for port in [80, 443, 8080, 8443]:
                protocol = "https" if port in [443, 8443] else "http"
                web_services.append({
                    "host": self.target,
                    "port": str(port),
                    "url": f"{protocol}://{self.target}:{port}"
                })
        
        # Analyze each web service
        web_results = {
            "services": [],
            "findings": []
        }
        
        if CONCURRENT_AVAILABLE:
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor:
                future_to_service = {executor.submit(self._analyze_web_service, service): service for service in web_services}
                
                for future in concurrent.futures.as_completed(future_to_service):
                    service = future_to_service[future]
                    try:
                        result = future.result()
                        if result:
                            web_results["services"].append(result["service"])
                            web_results["findings"].extend(result["findings"])
                    except Exception as e:
                        self.logger.error(f"Error analyzing web service {service.get('url')}: {str(e)}")
        else:
            # Sequential analysis if concurrent not available
            for service in web_services:
                try:
                    result = self._analyze_web_service(service)
                    if result:
                        web_results["services"].append(result["service"])
                        web_results["findings"].extend(result["findings"])
                except Exception as e:
                    self.logger.error(f"Error analyzing web service {service.get('url')}: {str(e)}")
        
        # Group findings by category
        grouped_findings = {}
        for finding in web_results["findings"]:
            category = finding.get("category", "Other")
            if category not in grouped_findings:
                grouped_findings[category] = []
            grouped_findings[category].append(finding)
        
        web_results["grouped_findings"] = grouped_findings
        web_results["total_findings"] = len(web_results["findings"])
        
        self.results["webapp_analysis"] = web_results
        self.logger.info(f"Web application analysis complete: {len(web_results['findings'])} findings")
        return web_results
    
    def _analyze_web_service(self, service):
        """
        Analyze a single web service
        
        Args:
            service (dict): Web service information
        
        Returns:
            dict: Service analysis results
        """
        if not REQUESTS_AVAILABLE:
            self.logger.error("Requests library not available, skipping web analysis")
            return None
        
        url = service.get("url")
        host = service.get("host")
        port = service.get("port")
        
        self.logger.debug(f"Analyzing web application at {url}")
        
        # Use the web analyzer from lib
        return webanalysis.analyze_web_service(host, port, url, verify_ssl=self.verify_ssl)
    
    def test_default_credentials(self):
        """
        Test for default credentials
        
        Returns:
            dict: Credential test results
        """
        self.logger.info("Testing for default credentials")
        
        cred_results = {
            "tested_services": [],
            "findings": []
        }
        
        # Extract services to test from recon results
        services_to_test = []
        if self.recon_results and "active" in self.recon_results and "ports" in self.recon_results["active"]:
            for host, host_data in self.recon_results["active"]["ports"].items():
                for proto, proto_data in host_data.items():
                    for port, port_data in proto_data.items():
                        service = port_data.get("service", "").lower()
                        
                        if service in ["http", "https", "ssh", "ftp", "telnet", "mysql", "mssql"]:
                            services_to_test.append({
                                "host": host,
                                "port": port,
                                "service": service,
                                "product": port_data.get("product", ""),
                                "version": port_data.get("version", "")
                            })
        
        # If no services found in recon, test common services
        if not services_to_test:
            for service in ["http", "https", "ssh", "ftp"]:
                port = {"http": "80", "https": "443", "ssh": "22", "ftp": "21"}.get(service)
                services_to_test.append({
                    "host": self.target,
                    "port": port,
                    "service": service
                })
        
        # Test each service
        if CONCURRENT_AVAILABLE:
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor:
                future_to_service = {executor.submit(validators.test_service_credentials, service): service for service in services_to_test}
                
                for future in concurrent.futures.as_completed(future_to_service):
                    service = future_to_service[future]
                    try:
                        result = future.result()
                        if result:
                            cred_results["tested_services"].append({
                                "host": service["host"],
                                "port": service["port"],
                                "service": service["service"]
                            })
                            
                            if result.get("findings"):
                                cred_results["findings"].extend(result["findings"])
                    except Exception as e:
                        self.logger.error(f"Error testing credentials for {service['service']} on {service['host']}:{service['port']}: {str(e)}")
        else:
            # Sequential testing if concurrent not available
            for service in services_to_test:
                try:
                    result = validators.test_service_credentials(service)
                    if result:
                        cred_results["tested_services"].append({
                            "host": service["host"],
                            "port": service["port"],
                            "service": service["service"]
                        })
                        
                        if result.get("findings"):
                            cred_results["findings"].extend(result["findings"])
                except Exception as e:
                    self.logger.error(f"Error testing credentials for {service['service']} on {service['host']}:{service['port']}: {str(e)}")
        
        cred_results["total_tested"] = len(cred_results["tested_services"])
        cred_results["total_findings"] = len(cred_results["findings"])
        
        self.results["credential_testing"] = cred_results
        self.logger.info(f"Credential testing complete: {len(cred_results['findings'])} findings from {len(cred_results['tested_services'])} services")
        return cred_results
    
    def generate_payloads(self):
        """
        Generate payloads for identified vulnerabilities
        
        Returns:
            dict: Generated payloads
        """
        # Use absolute import
        from lib import payloads
        
        self.logger.info("Generating payloads for identified vulnerabilities")
        
        payload_results = {
            "payloads": [],
            "payload_types": set()
        }
        
        # Generate payloads for validated vulnerabilities
        if "vulnerability_validation" in self.results and "vulnerabilities" in self.results["vulnerability_validation"]:
            vulns = self.results["vulnerability_validation"]["vulnerabilities"]
            
            for vuln in vulns:
                if vuln.get("risk_level") in ["critical", "high"]:
                    vuln_payload = payloads.generate_payload_for_vulnerability(vuln)
                    if vuln_payload:
                        payload_results["payloads"].append(vuln_payload)
                        payload_results["payload_types"].add(vuln_payload["type"])
        
        # Generate payloads based on web findings
        if "webapp_analysis" in self.results and "findings" in self.results["webapp_analysis"]:
            for finding in self.results["webapp_analysis"]["findings"]:
                if finding.get("risk_level") in ["critical", "high", "medium"]:
                    category = finding.get("category", "")
                    
                    finding_payload = None
                    
                    # Generate different payload types based on category
                    if category == "SQL Injection":
                        finding_payload = payloads.generate_sql_injection_payload(finding)
                    elif category == "Cross-Site Scripting (XSS)":
                        finding_payload = payloads.generate_xss_payload(finding)
                    elif category == "Local File Inclusion":
                        finding_payload = payloads.generate_lfi_payload(finding)
                    elif category == "Remote Code Execution":
                        finding_payload = payloads.generate_rce_payload(finding)
                    
                    if finding_payload:
                        payload_results["payloads"].append(finding_payload)
                        payload_results["payload_types"].add(finding_payload["type"])
        
        # Set payload counts and convert set to list
        payload_results["total_payloads"] = len(payload_results["payloads"])
        payload_results["payload_types"] = list(payload_results["payload_types"])
        
        self.results["payload_generation"] = payload_results
        self.logger.info(f"Generated {len(payload_results['payloads'])} payloads")
        return payload_results
    
    def identify_attack_vectors(self, exploit_filter=None):
        """
        Identify potential attack vectors based on findings
        
        Args:
            exploit_filter (dict): Filter for vulnerabilities by risk level
        
        Returns:
            list: Identified attack vectors
        """
        self.logger.info("Identifying attack vectors")
        
        attack_vectors = []
        
        # Process validated vulnerabilities
        if "vulnerability_validation" in self.results and "vulnerabilities" in self.results["vulnerability_validation"]:
            vulns = self.results["vulnerability_validation"]["vulnerabilities"]
            
            for vuln in vulns:
                risk_level = vuln.get("risk_level")
                
                if exploit_filter and "risk_level" in exploit_filter:
                    if risk_level not in exploit_filter["risk_level"]:
                        continue
                
                attack_vectors.append({
                    "type": "vulnerability",
                    "name": vuln.get("vulnerability"),
                    "target": f"{vuln.get('host')}:{vuln.get('port')}",
                    "service": vuln.get("service"),
                    "risk_level": risk_level,
                    "description": vuln.get("details", "No details available"),
                    "payload_available": any(p["type"] == vuln.get("vulnerability", "").lower() for p in self.results.get("payload_generation", {}).get("payloads", []))
                })
        
        # Process web app findings
        if "webapp_analysis" in self.results and "findings" in self.results["webapp_analysis"]:
            findings = self.results["webapp_analysis"]["findings"]
            
            for finding in findings:
                risk_level = finding.get("risk_level")
                
                if exploit_filter and "risk_level" in exploit_filter:
                    if risk_level not in exploit_filter["risk_level"]:
                        continue
                
                attack_vectors.append({
                    "type": "web",
                    "name": finding.get("finding"),
                    "target": finding.get("url", f"{finding.get('host')}:{finding.get('port')}"),
                    "category": finding.get("category"),
                    "risk_level": risk_level,
                    "description": finding.get("description", "No description available"),
                    "payload_available": any(p["type"] == finding.get("category", "").lower() for p in self.results.get("payload_generation", {}).get("payloads", []))
                })
        
        # Process credential findings
        if "credential_testing" in self.results and "findings" in self.results["credential_testing"]:
            findings = self.results["credential_testing"]["findings"]
            
            for finding in findings:
                if "credentials" in finding:
                    attack_vectors.append({
                        "type": "credentials",
                        "name": finding.get("finding"),
                        "target": f"{finding.get('host')}:{finding.get('port')}",
                        "service": finding.get("service"),
                        "risk_level": finding.get("risk_level"),
                        "description": finding.get("description", "No description available"),
                        "credentials": finding.get("credentials")
                    })
        
        # Sort attack vectors by risk level
        risk_order = {"critical": 1, "high": 2, "medium": 3, "low": 4, "info": 5}
        attack_vectors.sort(key=lambda x: risk_order.get(x["risk_level"], 99))
        
        self.results["attack_vectors"] = attack_vectors
        self.logger.info(f"Identified {len(attack_vectors)} potential attack vectors")
        return attack_vectors
    
    def generate_report(self, format="all"):
        """
        Generate report in specified format
        
        Args:
            format (str): Report format (json, excel, md, all)
        
        Returns:
            dict: Generated report filenames
        """
        reporter = reporting.ReportGenerator(
            results=self.framework.results,
            target=self.target,
            output_dir=self.output_dir
        )
        
        return reporter.generate_report(format=format, phase="preexploit")
